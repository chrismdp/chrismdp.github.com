---
layout: nil
---
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>Chris Parsons: posts tagged bdd</title>

  <link href="http://chrismdp.com/"/>
  <updated>2012-10-30T22:50:00+00:00</updated>
  <id>http://chrismdp.com/tag/bdd</id>
  <author>
    <name>Chris Parsons</name>
    <email>chrismdp@gmail.com</email>
  </author>
<entry><title>How to write a great story</title><category term='cucumber'/><category term='bdd'/><category term='bddkickstart'/><link href='http://chrismdp.com/2012/10/how-to-write-a-great-story'/><updated>2012-10-30T22:50:00+00:00</updated><id>http://chrismdp.com/2012/10/how-to-write-a-great-story</id><content type='html'>&lt;p&gt;Second in my mini-series of Cucumber videos: a quick introduction on writing a great story.&lt;/p&gt;

&lt;iframe width=&quot;445&quot; height=&quot;300&quot; src=&quot;http://www.youtube.com/embed/RJ3UiK1IEj4&quot; frameborder=&quot;0&quot;&gt;

&lt;/iframe&gt;

&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; This approach works best when starting off a brand new feature in the system. When changing existing features, we need to work to keep our preamble up to date. &lt;a href='http://blog.mattwynne.net/2010/10/22/features-user-stories/'&gt;Matt Wynne's blog post&lt;/a&gt; shows you how.&lt;/p&gt;

&lt;p&gt;If you like what you see, and you'd like to learn more, a quick reminder that Matt and I are running &lt;a href='http://bddkickstart.com'&gt;BDD Kickstart&lt;/a&gt; in London this coming December: the early bird ends November 4th.
&lt;/p&gt;
</content></entry><entry><title>The simplest Cucumber project ever</title><category term='cucumber'/><category term='bdd'/><category term='bddkickstart'/><link href='http://chrismdp.com/2012/10/the-simplest-cucumber-project'/><updated>2012-10-25T20:47:16+01:00</updated><id>http://chrismdp.com/2012/10/the-simplest-cucumber-project</id><content type='html'>Cucumber can be really very simple. Here's a short video to show how you can get started in two minutes flat, using only two files: a simple feature file, and a few lines of ruby to execute it.

&lt;iframe width=&quot;445&quot; height=&quot;300&quot; src=&quot;http://www.youtube.com/embed/8LtAmj17WtI&quot; frameborder=&quot;0&quot;&gt;

&lt;/iframe&gt;

&lt;p&gt;If you like what you see, and you'd like to learn more, a quick reminder that &lt;a href='http://mattwynne.net'&gt;Matt Wynne&lt;/a&gt; and I are running &lt;a href='http://bddkickstart.com'&gt;BDD Kickstart&lt;/a&gt; in London this coming December: the early bird ends November 4th.
&lt;/p&gt;
</content></entry><entry><title>Cucumber isn't a testing tool</title><category term='cucumber'/><category term='business'/><category term='bdd'/><category term='team'/><category term='testing'/><link href='http://chrismdp.com/2012/09/cucumber-isnt-a-testing-tool'/><updated>2012-09-19T17:41:22+01:00</updated><id>http://chrismdp.com/2012/09/cucumber-isnt-a-testing-tool</id><content type='html'>This is your periodic reminder that [Cucumber](/tag/cucumber) isn't a testing tool.

Here's what it actually is:

* *Cucumber is a great communication tool.* The great thing about collaborating on a cucumber feature is that the whole team get to stand in the same room and take part in the discussion. Everyone gets to argue about what should go in, what to keep out, and to help capture all the edge cases. The forming of the feature file facilitates that communication, with a great side effect of being able to check the finished feature still works at a later time. Cucumber excels as a communication tool, first and foremost: it's only incidentally a testing tool.

* *Cucumber captures conversations.* A feature file is a [bookmark](/2010/02/the-story-card-is-not-the-story) for the real feature: *the shared understanding of what needs to be done* that exists in the minds of the team. When the arm-waving and the arguments are done, a well written feature will expertly capture the essence of the conversation - the [semi-formal nature](http://dannorth.net/whats-in-a-story) of a feature acts as a checklist to ensure that we've talked about everything we need to.

* *Cucumber is for the team, not the developers.* Developers are often the gate-keepers of the feature files: if we're not careful we tend to write them, update them and run them without anyone else ever seeing them. We moan about how much more difficult features are to maintain than regular tests, whilst all the time we're missing the point: the features aren't for us, they're for those who can't read code!

For more on this, [watch this video](http://video2012.scotlandonrails.com/D1_LB_03-Ruby1280_b.mp4) ([slides](https://speakerdeck.com/u/chrismdp/p/cucumber-its-about-talking-not-testing)) from Scottish Ruby Conference where I explore these points in more depth. Remember that at its heart, Cucumber simply translates plain language into executing code. Its power lies in its ability to express code in plain language. Let's not reduce it to a mere testing tool, without letting the stakeholders see the features. If you're doing that, you're better off using RSpec.
</content></entry><entry><title>The power of feedback</title><category term='lean startup'/><category term='tdd'/><category term='bdd'/><category term='feedback'/><category term='lean'/><link href='http://chrismdp.com/2012/09/the-power-of-feedback'/><updated>2012-09-13T13:52:16+01:00</updated><id>http://chrismdp.com/2012/09/the-power-of-feedback</id><content type='html'>&lt;p&gt;&lt;i&gt;&quot;Everyone has a story that makes me stronger.&quot; -- Richard Simmons&lt;/i&gt;&lt;/p&gt;

There's something about feedback. Whether it's the validation of your latest idea, a hit on your webpage showing up on Google Analytics, or something as simple as a passing test, it's a valuable and important motivational commodity, which can also shape the direction in which we're going very precisely.

The effect of feedback is the engine at the root of software techniques as diverse as pairing, [TDD](http://en.wikipedia.org/wiki/Test-driven_development), [BDD](http://en.wikipedia.org/wiki/Behavior-driven_development) and the [Lean Startup movement](http://theleanstartup.com). Why is feedback so powerful?

## Feedback shortens the loop

Any sort of feedback represents the end of a creative loop that started when we began to work on whatever we're receiving feedback about. The shorter that loop, the more quickly we can respond to change, and the more agile we can be. It also helps us know when we're done working on something and it's time to move on.

That's partly why TDD is so powerful: we receive instant feedback on what we're working on and we are never more than a few minutes away from a fully working system. It's also why good quality customer feedback is powerful: we're never more than a few iterations away from the feature the customer wants.

## Feedback validates us and our work

The validation of our work is one of the things that lies at the root of [pairing](/2010/01/pairing-works-for-everthing): the constant code review and the camaderie keeps us motivated and working on something longer than we can manage on our own. I've found programming on [Sol Trader](http://soltrader.net) alone to be an enlightening experience - I've learnt how important it is to have others working alongside me. I now have a graphics expert reviewing my code, and more design and artistic help to keep me motivated to turn out releases.

It's also incredibly motivating to receive a &quot;thank you!&quot; or &quot;looks great!&quot; There's a lot of power in simple encouragement. If we know our work is appreciated and valued, we'll likely to work longer and with more energy on that next killer feature.

However, there's a danger in only seeking pure validation, or (worse) coming to rely on it for motivatioW. If we receive too much positive validation, we'll end up getting proud of ourselves and demotivated to push for excellence, and we'll get terminally discouraged if we get too little. We should be seeking the kind of feedback that motivates us to shape our work for the better. We have to learn to ask the right questions.

## Feedback shapes our work

If we let it, feedback will change the work we do and how we do it. This applies no matter how we receive feedback about our work - the different types of feedback will change our work in different ways, and we must therefore strive to increase both the quality and the variety of the feedback we receive, without falling into the trap of simple validation.

Done right, TDD offers more that just validation of our code; it gives us information about the quality of our code design. It causes us to shape our code differently and more carefully than code written without feedback. We can't operate in isolation though: TDD without feedback from stakeholders (whether that's through a technique such as Behaviour Driven Development or some other method) is incomplete: we get feedback that our code works, but nothing on whether it's the right code.

There's more: conversations such as [Lean Startup](http://theleanstartup.com/) are taking the BDD ideas one stage further. Instead of relying on the guesses of the stakeholders to determine what the right features are, how about harnessing feedback from the actual customers using the product? This can be done in various ways, through automatic metrics gathering and [tracking experiments rather than features](https://speakerdeck.com/u/chrismdp/p/lean-startup-validated-learning-and-kanban-for-hypothesis).

It's my opinion that the Lean Startup conversation is certainly as important as the BDD conversation, and potentially as important as the Agile conversation, as it improves the variety of the feedback we receive on our work.

How are you finding feedback shapes your work? Are you getting the right kinds of feedback from a variety of sources? Or are you settling for pure validation?
</content></entry><entry><title>Kickstart your team on BDD</title><category term='bddkickstart'/><category term='bdd'/><category term='cucumber'/><category term='code'/><category term='ruby'/><link href='http://chrismdp.com/2012/07/kickstart-your-team-on-bdd'/><updated>2012-07-27T08:13:22+01:00</updated><id>http://chrismdp.com/2012/07/kickstart-your-team-on-bdd</id><content type='html'>[Matt Wynne](http://mattwynne.net) and I have been running courses on BDD for the BBC Future Media division for the past year or two. They've been extremely well received, so we've decided to open them up to the wider public so everyone can benefit.

The full details are at [bddkickstart.com](http://bddkickstart.com), but read on for a bit more info:

## When/where is it?

There are four seperate day-long workshops running in October, from 8th - 11th in Central London near Trafalgar Square. You can just come to one day, or all four.

## What's the course material?

Day 1 is entitled &quot;Just enough Ruby&quot;. It teaches programmers from other languages the basics of Ruby so that they are comfortable using cucumber effectively.

Day 2 is a BDD workshop for the whole team. It builds awareness and enthusiasm for the concepts with a chance to practice collaboration in the way that makes BDD work.

Day 3 is a practical day for programmers to learn about Cucumber: what it is, what it isn't, and how to write good cucumber code that can be maintained over time.

Day 4 covers advanced BDD concepts and common pitfall people find when using these techniques in the real world.

## Do I have to sign up for all four days?

No, you can pick and choose, and just come to one day if you like. There's a small per day discount if you book all four days.

## So which days are for me?

&lt;p&gt;if you're a &lt;strong&gt;developer with Ruby experience&lt;/strong&gt;, you might want to skip the first day and come along to days 2, 3 or 4.&lt;/p&gt;

&lt;p&gt;If you are a &lt;strong&gt;Product Owner, Business Analyst, Project Manager or UX specialist&lt;/strong&gt;, come along to just day 2, and understand why BDD is designed for you guys in the first place!&lt;/p&gt;

&lt;p&gt;If you're a &lt;strong&gt;keen developer but not necessily very experienced in Ruby&lt;/strong&gt;, you should consider the &lt;a href=&quot;http://bdd.eventbrite.co.uk&quot;&gt;full four day course&lt;/a&gt;. We'll take you through the basics of Ruby, the reasons behind doing development this way, how to use Cucumber properly (saving you time in the long run) and some neat advanced tricks.&lt;/p&gt;

## Are you running early bird tickets, or promotions?

Glad you asked: if you use the code &lt;strong&gt;super-early-birdy&lt;/strong&gt; you'll get 20% of the list price until 1st August, just for reading this far down the page :)

## How can I find out more or book my place?

You can find more info and book at [bddkickstart.com](http://bddkickstart.com), or [send us mail](mailto::hello@bddkickstart.com) if you have specific questions.

Hope to see you in October!
</content></entry><entry><title>Feature writing: multiple actors</title><category term='bdd'/><category term='cucumber'/><category term='code'/><link href='http://chrismdp.com/2011/12/feature-writing-multiple-actors'/><updated>2011-12-08T11:01:23+00:00</updated><id>http://chrismdp.com/2011/12/feature-writing-multiple-actors</id><content type='html'>I've [written a fair amount](/tag/cucumber) in the past about Cucumber and the way I like to structure my features. After reading these through, someone recently asked me about a particular workflow concerning multiple actors.

They were starting from the following feature file:

{% highlight cucumber %}
Feature: Complimentary Accounts

Scenario: Creating a complimentary account
  Given I am signed-in to the admin area
  When I create a new complimintary account with these details:
    | Name  | John Smith           |
    | Email | john.smith@gmail.com |
  Then a welcome email should be sent to 'john.smith@gmail.com'

Scenario: Receiving a welcome email
  Given I have received a welcome email
  When I follow the link
  Then I should see a welcome page
  And I should be signed-in
  And I should see the details of my account
  And I should be able to set my password
{% endhighlight %}

The concern was that the feature had more than one actor involved: there was the administrator creating the complimentary account, and the recipient of that account. The feature as written just didn't feel right to them: it's not clear who the actors are from the text, although the feature has a certain workflow. Also the check that recipient can set the password is an important one, but isn't clearly called out in the feature.

How could this be written differently?

## Setting the scene

The first thing I noticed is that the feature is missing a preamble. People often leave these out, but I find them invaluable to set the context of the feature and to ensure there's a point to adding the feature at all.

To write the scenarios, I would approach this from the point of view of the personas involved, who I would [normally give names](/2011/04/cucumbers-with-personality). In this case there are two obvious personas: Angie the Administrator, and Victor the VIP. There's a more subtle role at play here too: It's unlikely that Angie decides who gets a complimentary accoun. Therefore we also have the particular stakeholder who wants this feature, who we will call Buster the Business Development Director.

This is how I'd structure the &quot;non-executing&quot; part of the feature:

{% highlight cucumber %}
Feature: Complimentary Accounts
  In order to cater for certain special people that promote our
    company in other ways
  As Buster the Business development director
  I want the ability to ask Angie the Administrator to create
    special free accounts for special people

  Scenario: Angie creates a complimentary account
    ..
  Scenario: Victor receives a welcome email
    ..
  Scenario: Victor can change his password
    ..
{% endhighlight %}

I'd check this with the customer too, just to make sure it made sense. If the password changing is important to them, I'd make that a separate scenario.

## Writing the scenarios

I keep my [scenarios really short](/2011/09/layers-of-abstraction-writing-great-cucumber-code). So I'd try and push some of these details down into steps. Let's take the scenarios in turn:

{% highlight cucumber %}
@angie
Scenario: Angie creates a complimentary account
  When I create a new complimintary account for Victor
  Then a welcome email should be sent to Victor
{% endhighlight %}

The `@angie` tag just ensures that Angie is signed in. It's neater than a separate `Given` step in my opinion. I don't include specifics such as email addresses: it's just noise.

{% highlight cucumber %}
@victor
Scenario: Victor receives a welcome email
  Given I have received a welcome email
  When I follow the link
  Then I am logged straight into my account
{% endhighlight %}

The fact that we've switched actor here isn't a problem in my view. It's still clear who &quot;I&quot; is in this case, because the scenario title is clear and descriptive.

{% highlight cucumber %}
@victor
Scenario: Victor receives a welcome email
  Given I have received a welcome email
  When I follow the link
  Then I can change my password from the first screen
{% endhighlight %}

This is a very similar scenario, but it's worth making it a separate one as the password change is an important business need for the customer. It's very tempting to tag the check onto the end of a previous scenario, but this reduces clarity and the perceived importance of that particular part of the feature in everybody's mind.

Feature files are [bookmarks for conversation](/2010/02/the-story-card-is-not-the-story) in just the same way that other agile tracking methods are. If they don't accurate represent the shared thinking, they're worse than useless.

## Get the customer input

I'm not sure if this feature had originally been run past the customer, but this point is so important that it's worth restating anyway:

*If you're not showing the customer the feature files you're missing out on 90% of the value of Cucumber.*

I'm still sometimes guilty of not doing this. I feel like I must have covered every detail and that discussing it with a customer is a waste of time, but I can't remember ever showing a feature file to a customer where we didn't change the feature to make it better. There's always some ambiguity you [can drive out](/2010/01/driving-out-feature-ambiguity).

&lt;p&gt;&lt;i&gt;Have you got any feature files you'd like some input on? Send them over and I'll do my best to give some insight if I can.&lt;/i&gt;&lt;/p&gt;

</content></entry><entry><title>How I'm testing iPhone apps: part 2</title><category term='code'/><category term='ios'/><category term='tdd'/><category term='bdd'/><category term='testing ios'/><link href='http://chrismdp.com/2011/12/how-im-testing-iphone-apps-part-2'/><updated>2011-12-06T16:02:54+00:00</updated><id>http://chrismdp.com/2011/12/how-im-testing-iphone-apps-part-2</id><content type='html'>&lt;p&gt;&lt;i&gt;I've recently been doing some iOS development, and working out the best way to test-drive the development of iOS apps was high on my priority list. I know that the automated testing of iOS applications is still not widely practiced and isn't well documented, so I decided to write a series of posts to start to rectify that. You may wish to read &lt;a href=&quot;/2011/12/how-im-testing-iphone-apps-part-1&quot;&gt;part 1&lt;/a&gt; first.&lt;/i&gt;&lt;/p&gt;

## Kiwi

We were looking for a testing framework which supported iOS's asynchronous programming model and [Kiwi](https://github.com/allending/Kiwi) answered the call. It has a great syntax, [comprehensive set up assistance](https://github.com/allending/Kiwi/wiki/Guide:-Up-and-Running-with-Kiwi), asynchronous support and built in mocking. I'd highly recommend you check it out: the syntax helps me to think in the right way and it has pretty much all the features we needed.

Kiwi's block syntax looks like this:

{% highlight objectivec %}
describe(@&quot;Team&quot;, ^{
    context(@&quot;when newly created&quot;, ^{
        it(@&quot;should have a name&quot;, ^{
            id team = [Team team];
            [[team.name should] equal:@&quot;Black Hawks&quot;];
        });
    });
});
{% endhighlight %}

Much better than the old fashioned xUnit style of testing, in my opinion. You might hate it, of course. You can use Kiwi's features [without having to use the block syntax](https://github.com/allending/Kiwi/issues/73) if you want.

## Objective-C's delegate model

Many of the Apple core libraries use a delegate pattern for handling callbacks from a class. This is similar to Java's interfaces, and superficially similar to blocks in Ruby and anonymous functions in Javascript.

As an example, let's take CoreLocation. When wanting to find the location of a phone, you create a new `CoreLocationManager` and call `startUpdatingLocation` on it:

{% highlight objectivec %}
CLLocationManager *manager = [[CLLocationManager alloc] init];
[manager startUpdatingLocation];
{% endhighlight %}

This call returns immediately: so how do you execute code when the location is found? You use a delegate: an object with responds to the `locationManager: didUpdateToLocation: fromLocation` method:

{% highlight objectivec %}
-(void)locationManager:(CLLocationManager *)manager didUpdateToLocation:(CLLocation *)newLocation fromLocation:(CLLocation *)oldLocation
{
  NSLog(&quot;$@ I AM IN YOU&quot;, newLocation);
  foundLocation = YES;
}
{% endhighlight %}

Then you set this object to be the CLLocationManager's delegate before calling `startUpdatingLocation`. Often you set the delegate to `self` and define the delegate method on the calling object.

{% highlight objectivec %}
CLLocationManager *manager = [[CLLocationManager alloc] init];
manager.delegate = self;
[manager startUpdatingLocation];
{% endhighlight %}

There's more about this model in [this article from Apple](http://developer.apple.com/library/IOs/#documentation/iPhone/Conceptual/iPhone101/Articles/02_DesignPatterns.html).

## Testing delegates

This is tricky to test, because we can't simply do this:

{% highlight objectivec %}
it(&quot;should call the delegate when ready&quot;, ^{
  [testObject startUpdatingLocation];
  [[testObject.foundLocation should] equal:theValue(YES)];
});
{% endhighlight %}

The test will call `startUpdatingLocation`, and then immediately check the `foundLocation` property to see whether it's been set. It won't have been, because the delegate won't have been called yet.

How were we to stub endpoints such as the location system for for our app? We found two ways of doing this, with varying effectiveness:

* Using Objective-C categories to redefine class methods
* Using a Kiwi stub to inject a derived class which mocks out key methods

Next post, I'll dive into some detail on both of these methods and show some of the pros and cons of each.

&lt;i&gt;How are you testing iPhone apps? Do chime in throughout the series with suggestions and comments, and I'll edit the posts as appropriate.&lt;/i&gt;

</content></entry><entry><title>How I'm testing iPhone apps: part 1</title><category term='code'/><category term='ios'/><category term='tdd'/><category term='bdd'/><category term='testing ios'/><link href='http://chrismdp.com/2011/12/how-im-testing-iphone-apps-part-1'/><updated>2011-12-01T22:45:35+00:00</updated><id>http://chrismdp.com/2011/12/how-im-testing-iphone-apps-part-1</id><content type='html'>&lt;p&gt;&lt;i&gt;This week I've been working with &lt;a href='http://shilling.co.uk'&gt;Shilling&lt;/a&gt; helping them get starting with iOS application development. Part of the deal was for me to learn it myself as we went: I've done hardly any iOS work and we've been learning how to do it together.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;As part of this process, working out the best way to test-drive the development of iOS apps was high on my priority list. I know that the automated testing of iOS applications is still not widely practiced and isn't well documented, so I decided to write a series of posts to start to rectify that.&lt;/i&gt;&lt;/p&gt;

## Our goal

There are two main parts to working out how to test-drive applications on a new platform. One is to figure out the testing libraries and write simple `1 + 1 = 2` style tests to prove it can be done. The other half is working out how to apply common testing techniques such as stubbing external systems, isolating tests correctly and optionally driving the interface.

The first of these steps is quite easy on iOS, but the second part is harder. In our case, we have some code which makes use of CoreLocation and the [Geonames](http://geonames.org) service to get an iPhone's location and look up the county name from a latitude and longitude. This means that our code relies on two external services to run, which we want to stub out: we don't want these services to be called each time our tests run. How were we to set this up correctly?


## Apple's documentation

To kick off our testing adventure on iOS, we started with [Apple's own public documentation](http://developer.apple.com/library/ios/#documentation/Xcode/Conceptual/ios_development_workflow/135-Unit_Testing_Applications/unit_testing_applications.html) on how to test iOS. This is a fairly comprehensive guide on how to set up a project with built in testing, allowing you to write basic SenTest tests quite quickly.

Apple divides its definition of unit testing into two categories:

* Logic tests: these are what I would normally call unit tests. They rely on very few external APIs and are run standalone without the use of a simulator.
* Application tests: these are executed in the context of a running application on a simulator or iOS device.

The document details how to set up both types in your project. There's a few things missing though:

* They have good ideas about [how to write decent tests](http://developer.apple.com/library/ios/#documentation/Xcode/Conceptual/ios_development_workflow/135-Unit_Testing_Applications/unit_testing_applications.html#//apple_ref/doc/uid/TP40007959-CH20-SW12), but lack information on how to correctly mock system endpoints. I want to do this so that I don't have to rely on iOS location simulation, or HTTP response data, to make my tests work.
* There was also nothing on how to test asynchronously, which is a real problem as iOS applications are mostly written in this way.
* Application tests are executed in the context of your application, but without extra work it's not possible to support native UI testing, [Capybara](https://github.com/jnicklas/capybara) style. We are reduced to manipulating controllers directly, which is good enough for now. This assumes you have your user interface wired up correctly. As the app always has to be tested manually anyway then this isn't too much of a risk, but if you want to take a step further you could use [KIF](https://github.com/square/KIF), [Frank](https://github.com/moredip/Frank) or Apple's own [UIAutomation](http://developer.apple.com/library/ios/#documentation/DeveloperTools/Reference/UIAutomationRef/Introduction/Introduction.html). There's a good post comparing them [here](http://sgleadow.github.com/blog/2011/10/26/which-automated-ios-testing-tool-to-use/).

So we followed through the basic set up instructions, and got a simple test running which added two numbers together. A good start, but useless for real work.

Time to go in search of an asynchronous testing framework: and we found a great one. Next time, I'll talk about the wonderful [Kiwi](https://github.com/allending/Kiwi).

&lt;i&gt;How are you testing iPhone apps? Do chime in throughout the series with suggestions and comments, and I'll edit the posts as appropriate.&lt;/i&gt;
</content></entry><entry><title>Your tests are lying to you</title><category term='code'/><category term='cucumber'/><category term='craftsmanship'/><category term='bdd'/><category term='rspec'/><category term='rails'/><link href='http://chrismdp.com/2011/10/your-tests-are-lying-to-you'/><updated>2011-10-17T19:10:29+01:00</updated><id>http://chrismdp.com/2011/10/your-tests-are-lying-to-you</id><content type='html'>Using mocks within your test suite has gone rather out of fashion. Programmers everywhere have been lamenting the fact that mock-based tests are becoming more and more brittle: they're having to change the test code in multiple places each time there's the slightest code change. In fact, they seem to be changing the test code much much more often than the production code.

Using mocks appear to require a lot of set up code for the object under test. Why not just fire up Factory Girl, create a bunch of objects we need to test this code, and just check the outputs?

This works, and appears to work nicely. For a while.

Eventually your tests will get to the point where they're lying to you: they're telling you your code works whereas actually it only works by coincidence. This post will examine the different techniques we can use to test code, and why some work better than others in the long term.

## The problem

To look at this further, let's try to write a conference simulator for a new website that tries to predict how many people might attend an upcoming event: 

{% highlight ruby %}
describe Conference do
  it &quot;calculates total rating&quot; do
    conference = Conference.new(:total_rating =&gt; 9)
    conference.total_rating.should == 9
  end
end
{% endhighlight %}

A simple start, with equally simple production code. Next, we decide to extract our code for calculating the rating into &lt;code&gt;Speaker&lt;/code&gt; classes. We decide not to change the test suite much, and make the code work behind the scenes:

{% highlight ruby %}
describe Conference do
  it &quot;calculates total rating&quot; do
    conference = Conference.new(:speakers =&gt; [:chris, :paul])
    conference.total_rating.should == 9
  end
end
{% endhighlight %}

A nice simple, easy change? You'll pay for this later. Where is the Speaker coming from? Your Conference class is creating it somewhere, or retrieving it from a factory. You've increased the number of collaborators for this class by at least one (possibly three), yet your test isn't showing the additional complexity. It's deceitfully hiding it, whilst you continue on in blissful ignorance.

Your tests are now sitting around the outside of your system. There are no tests for the Speaker class at all, except that we co-incidentally check the rating it emits. Another developer is likely to miss the connection and remove the implied test whilst changing the code for a different reason later.

This gets worse over time:

{% highlight ruby %}
describe Conference do
  it &quot;calculates total rating&quot; do
    conference = Conference.new(
      :schedule =&gt; :nine_to_five,
      :talks =&gt; [talk_for(:chris), talk_for(:paul)]
    )
    conference.total_rating.should == 9
  end
end
{% endhighlight %}

Can you see what's going on here? We've created some nice helper methods to make it easy to create the required talk objects we need. This test is fairly easy to read, but it's dressing up the problem. The test code is relying on far too many collaborators to function correctly to return the correct result.

When you extract a class, your purely state based tests don't always require change. If you're not stubbing out or mocking systems, you can end up in a situation where you're relying on the code to work without realising it.

How could it be improved?

{% highlight ruby %}
describe Conference do
  let(:talk1) { double(:talk, :rating =&gt; 10) }
  let(:talk2) { double(:talk, :rating =&gt; 6) }
  let(:schedule) { double(:schedule, :rating =&gt; 10) }
  before(:each) { Schedule.stub(:new =&gt; schedule) }
  it &quot;calculates total rating&quot; do
    conference = Conference.new(
      :schedule =&gt; :nine_to_five,
      :talks =&gt; [talk1, talk2]
    )
    conference.total_rating.should == 9
  end
end

describe Speaker do
end
describe Schedule do
end
{% endhighlight %}

Now we've isolated the method nicely from its collaborators, and ensured that its behaviour is correct: that it aggregates the ratings of the talks and the schedule. We also make sure that we're testing Conference correctly, also in isolation.

The more you use refactoring methods such as Extract Class without cleaning up your tests, the more likely your tests will be lying to you. Little by little, those tests that you trusted are slowly testing more and more code. You add a multitude of edge cases at the edges, never thinking about the complexity within. You've resorted to using end-to-end tests to test basic correctness.

This is a bad thing on many levels: for example, what happens to interface discovery? How will you know how the interface of your lower-level classes needs to behave if you're not mocking or stubbing it? You are resorting to guessing, rather than exercising the interface ahead of time in your tests. If you have tests around the edges, but not in the middle, you're not gaining the design input that tests give you in each layer of your system.

## Your code stinks

If you go the whole hog with testing in isolation, then you might end up here with something like this:

{% highlight ruby %}
describe Conference do
  let(:talk1) { double(:talk, :rating =&gt; 10) }
  let(:talk2) { double(:talk, :rating =&gt; 6) }
  let(:talk3) { double(:talk, :rating =&gt; 2) }
  let(:talk4) { double(:talk, :rating =&gt; 8) }
  let(:track1) { double(:track, :talks =&gt; [talk1, talk3] }
  let(:track2) { double(:track, :talks =&gt; [talk2, talk4] }

  let(:venue1) { double(:venue, :nice_coffee_places =&gt; 3) }

  let(:joe) { double(:announcer, :experience =&gt; 5) }

  let(:schedule) { double(:schedule, :rating =&gt; 10, :accouncer =&gt; joe) }
  before(:each) { Schedule.stub(:new =&gt; schedule) }

  it &quot;calculates total rating&quot; do
    conference = Conference.new(
      :schedule =&gt; :nine_to_five,
      :tracks =&gt; [track1, track2],
      :organiser =&gt; joe,
      :venues =&gt; [venue1, venue1]
    )
    conference.total_rating.should == 6.3945820
  end
end

{% endhighlight %}

I'm not surprised people moan about maintaining this: if any aspect of the Conference class changes, this test will break and need to be fixed. We can see that this test code is hard to write and difficult to read. It would be so much easier just to hide this setup in a few factory methods with some sensible defaults, right?

Maybe it's not the test code that's the problem. Perhaps the code stinks. Perhaps the class simply has way too many collaborators, which is why your test code contains a large amount of set up.

For this test code, we can see there are several objects leaking all over the conference code: to refactor this I'd probably get through a Scheduler, Caterer and perhaps a TrackAggregator before I was done. I'd ensure all these objects were tested in isolation, and ensure that there are acceptance tests all the way through to make sure the customer has what they need.

_Well designed code is easy to test._ As a rule of thumb, anytime I get over about two or three lines of setup code for testing a method, I normally take a step back and ask myself if this method is doing too much.


## Test speed

The other advantage of running tests purely in isolation is that they're fast. Very fast. When I'm coding Rails apps these days, thanks to advice from [Corey Haines](http://twitter.com/coreyhaines) I'm running a &lt;code&gt;spec_no_rails&lt;/code&gt; folder which runs independently from the rest of my Rails app. Rails apps by default epitomise this problem: default model tests exercise the whole system from the database up. By running your tests independently you're not having to clean the database or start Rails each time you run your tests, which means that much of your interesting code can be tested in under a second. [Gary Bernhardt](http://twitter.com/garybernhardt) has more information on how to set this up in his excellent [Destroy All Software](http://destroyallsoftware.com) screencast series.

## What I'm not saying

This isn't an argument for or against Mocks or Stubs. Either technique can be used successfully to generate clean code. It's an argument about only exercising the code under test, and leave the rest of the system to take care of itself. The important thing is that you _don't exercise your collaborators:_ whether you check they've received messages or simply stub them to return input doesn't matter.

*Don't forget end-to-end tests.* These are very important for business acceptance and for ensuring basic functionality. The important thing is to ensure that you're being intentional about your end-to-end tests and ensure your unit tests are not end-to-end tests by accident.

Take a good look at the test code for a project you recently worked on. You don't need to look at the production code yet: notice that I've not included any production code in these examples. You shouldn't need to see it to know whether it's of good quality or not: you can tell that by reading the tests.

Which is the most annoying or bulky part of your test code? Are your tests deceiving you about what they're testing? How could you improve the code to make this test code easier to maintain?
</content></entry><entry><title>Layers of abstraction: writing great cucumber code</title><category term='bdd'/><category term='cucumber'/><category term='agile'/><category term='ux'/><link href='http://chrismdp.com/2011/09/layers-of-abstraction-writing-great-cucumber-code'/><updated>2011-09-15T07:44:41+01:00</updated><id>http://chrismdp.com/2011/09/layers-of-abstraction-writing-great-cucumber-code</id><content type='html'>I blogged about Gojko's thoughts on layers of abstraction [a week or so ago](/2011/09/layers-of-abstraction-bdd-ux), discussing three different ways we can think about the behaviour of any system. These way are: the business rules, the workflow of that system, and the specific activity the user is undertaking.

Today I want to think about how we can leverage these insights to help us write really good cucumber features and step code.

## I used to write terrible features

Do these look familiar?

{% highlight cucumber %}
Feature: Paul pays employees
  In order to retain staff
  As Paul the Payroll Manager I want to pay my staff

Scenario:
  Given an admin user called &quot;Paul&quot; with a password &quot;password&quot;
  And a user called &quot;Bob&quot;
  And &quot;Bob&quot; is an employee
  And &quot;Bob&quot; gets paid &quot;$2,000&quot; a month
  When I visit the homepage
  And I click on &quot;Log in&quot;
  And I fill in &quot;username&quot; with &quot;Paul&quot;
  And I fill in &quot;password&quot; with &quot;password&quot;
  And I click &quot;Log in&quot;
  And I click &quot;Payroll&quot;
  And I click &quot;Bob&quot;
  And I click &quot;Pay&quot;
  And I enter &quot;$2,000&quot;
  And I click &quot;Pay&quot;
  Then I should see &quot;Bob has been paid&quot;
{% endhighlight %}

We've all written features like this in the past: there's [plenty](http://benmabey.com/2008/05/19/imperative-vs-declarative-scenarios-in-user-stories.html) [of](http://dannorth.net/2011/01/31/whose-domain-is-it-anyway/) [guidance](http://elabs.se/blog/15-you-re-cuking-it-wrong) out there these days to help you write better features than this. However, rather than just accept &quot;best practices&quot; at face value, let's take a look under the hood and work out *why this is better.*

## Variance revisited

Last time I discussed this topic, I mentioned the key differentiator was variance. Business rules are unlikely to change significantly unless the company decides to pivot: this is more likely in a startup but still less likely overall. The workflow is normally fairly static, but the activity the user follows changes regularly.

Co-incidentally, there are three levels of behaviour implementation that we write when we work with Cucumber:

* *The feature files.* Ideally there are written in collaboration with the customer and are written out before coding begins.

* *The step definitions.* We implement each step of our feature with ruby code as we are writing the feature, sometimes reworking existing steps to be more powerful (often at our peril).

* *Support code.* Cucumber executes our steps inside a 'world object', which we can easily extend through the adding of modules and methods.

Each of these implementation levels is also differentiated in terms of variance:

* *The feature files are the most difficult to change,* as this ideally requires a conversation with the customer, and any wording changes have a knock on effect on step definitions.

* *Step definitions can be tricky to change,* especially if they are used by multiple feature files. Their implementation is closely tied to the regular expression they match, which can make them difficult to understand if highly reused: one case where Don't Repeat Yourself can fall down quickly.

* *Support code is easy to change* as it's plain ruby and as such very malleable: we can easily refactor and be careful with our naming to tease out duplication.

## Where to put the code?

If it's easy to change support code, then it follows that we should put our higest varying code there: namely the code which describes specific activity. Normally only programmers are interested in this code and it's easy enough to find and understand if the support methods are well-named.

The workflow code lives best in individual steps which aren't often reused and which have simple regular expressions. The people who are interested in this area are normally designers and User Experience people, who should be able to read well-named ruby code at a pinch and therefore can understand what's going on.

The code that's least likely to change (the business rules) can safely live in the feature files with impunity, where it can be discussed with product owners. The product owner is most interested in the rules of their system: they're only moderately interested in the workflow and usually aren't too opiniated about the specific activities. That's partly why we struggle to write features with our clients: if we're trying to discuss activity specifics like in the example feature above, we're probably nailing down details too early and bore our product owner to tears. It's hard enough for a programmer to read these sorts of features: how can we expect anyone else to understand them?

## An example

Given this, how would I refactor the feature above to improve things? After deleting web\_steps.rb, I would rewrite the feature with my customer citing the business rule, rather than any specific workflow:

{% highlight cucumber %}
Feature: Paul pays employees
  In order to retain staff
  As Paul the Payroll Manager I want to pay my staff

@paul_signed_in
Scenario:
  Given an employee called &quot;Bob&quot;
  Then I should be able to pay &quot;Bob&quot; his salary
{% endhighlight %}

My step definitions would look something like this:

{% highlight ruby %}
Given /^an employee called &quot;([^&quot;]+)&quot;$/ do |employee_name|
  create_employee(employee_name)
end

Then /^I should be able to pay &quot;([^&quot;]+)&quot; his salary$/ do |employee_name|
  pay_salary_to(employee_)
end
{% endhighlight %}

And the support code might look roughly like this:

{% highlight ruby %}
Before(&quot;paul_signed_in&quot;) do
  paul = create_employee(&quot;Paul&quot;)
  paul.assign_role(&quot;payroll&quot;)
  sign_in_as(paul)
end

def create_employee(name)
  Employee.create!(:name =&gt; name, :username =&gt; name,
    :password =&gt; &quot;password&quot;)
end

def pay_salary_to(name)
  payee = Employee.find_by_name(name)
  visit payroll_employee_path(payee)
  fill_ :salary, :with =&gt; payee.salary
  click_button &quot;Pay&quot;
end
{% endhighlight %}

You're also free not to test the UI if you'd prefer not to in your support code. However, as we've given ourselves the ability to remove duplication, it's easy to change the code when the UI changes. So far I've not found UI brittleness to be too much of an issue.

## In conclusion

These are rules of thumb, but they can be very helpful in keeping the rate of development up as our codebase expands. One change that I've made recently to my own practice is to be more aggressive at pushing activity code down into support code, and it's really helped to keep feature code flexible and easy to change.

Many people have given up on Cucumber, citing long build times and the brittleness of the test code as primary reasons. Obie Fernandez recently [blogged](http://blog.obiefernandez.com/content/2011/05/the-dark-side-beckons.html) about finding &quot;high-ceremony&quot; development too much work in a startup. I think that's a real shame: it's a fantastic way to drill down to specific behaviour and ensure you're only building what you need. If you think about the behaviour of your system correctly, aggressively remove duplication in all your code (including test code), and only test code you own then you shouldn't be burdening yourself with too much of an overhead.

Have you given up using Cucumber? Or if you use it, is this the way you do it or do you have a better method?

</content></entry><entry><title>Layers of abstraction: combining BDD and UX</title><category term='bdd'/><category term='cucumber'/><category term='agile'/><category term='ux'/><link href='http://chrismdp.com/2011/09/layers-of-abstraction-bdd-ux'/><updated>2011-09-05T20:44:03+01:00</updated><id>http://chrismdp.com/2011/09/layers-of-abstraction-bdd-ux</id><content type='html'>I first came across [Gokjo Adzic's thoughts on the different levels of UI test automation](http://gojko.net/2010/04/13/how-to-implement-ui-testing-without-shooting-yourself-in-the-foot-2/) some time ago: it's a really nice way to think not just about test automation, but about the different levels of behaviour in any software project.

I've been considering the similarities between these levels of behaviour and the user experience discipline, and how we might leverage that thinking to iterate towards a better way of combining agile methods with UX.

## Three ways to think of behaviour

Applying these rules to any software system gives us three ways to think about the behaviour of that system.

*The business rules.* These are high level and abstract. To take the example of a Payroll system: the business rules represent such things as &quot;Staff members always get paid on the last Friday of the month&quot;, or &quot;Temporary staff workers must submit a timesheet before being paid.&quot;

*The workflow.* The workflow represents the logical steps a user might go through to fulfil a business rule. For example: &quot;As a HR person, I want to see a list of temporary workers and pay those who are shown to have submitted a timesheet.&quot;

*The specific activity.* The detailed steps a user goes through to achieve the workflow: &quot;I click on the 'show temp workers' link; I see an icon next to those who have submitted timesheets, along with the last date they submitted; I click the 'Pay' button...&quot;

The key differentiator here is *variance.* The business rules of a system are the least likely to change: changing these might represent a [pivot](http://venturebeat.com/2010/04/14/business-plan-not-working-time-to-pivot/) and will incur significant development cost.

The specific activities change most often: perhaps at a designer's whim, or through localisation or other text changes. We should therefore strive to ensure that changing the activities incurs as small a development cost as possible.

## The agile / user experience process is similar

If you think about it, the three layers represent the different and progressive stages of thinking that we go through when designing the user experience of new applications.

*Business rules of the system are laid down by the product owner at the start of a project.* When considering the user experience of the application, we are careful to first understand a high level overview of the purpose of the software, getting as much useful information as possible from the product owner at an inception.

*Workflow design is led by the UX team and happens when a new story is created.* When creating a new slice of functionality, we carefully think through the workflow of that particular feature, using wireframing, [personas](/2011/04/cucumbers-with-personality) or [whatever works](/2010/02/the-story-card-is-not-the-story) combined with [lots of discussion](/2010/02/the-story-card-is-not-the-story). The net result is a basic step by step workflow of the new feature, without too much detail added.

*Specific activities are created by developers and graphic designers.* Developers and designers make a thousand little decisions about the user experience of the application as they build the feature, hopefully discussing their thoughts with the UX experts on their team if they feel out of their depth.

## From general to specific

As we create features, we are iterating from the general to the specific; from the high level to the detail. To determine all the granular behaviour up front (and all the precise graphical designs) is inefficient: we are likely to change our minds about the detail. Yet this is what many user experience practioners and designers try to do: if not for the whole project, then for whole sections of the project.

For example, if you're doing more than a dozen wireframes or so in advance, are you doing too much thinking ahead of time? Why not resist, have more agility, and let the completion of some of the features guide your future thinking? Likewise, I have often been presented with dozens of perfect photoshop mockups to code up, often without any clear direction on the behaviour represented within them. It is more agile to keep things as high level as possible for as long as possible. How about producing a guidance mockup and a style guide, and then sitting down and guiding the developers on the design when they come to build the feature?

This doesn't mean you can avoid the detail. You need both ends of the behaviour spectrum: neglect the detail of the experience and you [settle for mediocrity](/2010/05/ux-is-everything). Conversly if we neglect the high level our application becomes a ship without a rudder and the user experience will become confused.

In the future I plan to discuss how the use of [Cucumber](http://cukes.info) fits in to this, and how we can progressively iterate our cucumber features as we get more and more specific about a particular feature.
</content></entry></feed>
